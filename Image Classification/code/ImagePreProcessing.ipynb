{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Image Preprocessing\n",
    "\n",
    "In order to run all of the neural networks with the same set of images, we will do all of our image preprocessing and augmentation beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "from PIL.ImageOps import mirror\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_pth = os.getcwd() + '/../data_raw/train/'\n",
    "train_data_out = os.getcwd() + '/../data/train/'\n",
    "validation_data_pth = os.getcwd() + '/../data_raw/validation/'\n",
    "validation_data_out = os.getcwd() + '/../data/validation/'\n",
    "img_width, img_height = 80, 80\n",
    "input_shape = (img_width, img_height, 3)\n",
    "folders = ['bart', 'hommer', 'lisa', 'marge']\n",
    "skew_fraction = 0.1\n",
    "zoom_fraction = 0.2\n",
    "n_input = 30 #300\n",
    "n_valid = 6  #50\n",
    "random_permutations_per_image = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on directory: bart\n",
      "Working on directory: hommer\n",
      "Working on directory: lisa\n",
      "Working on directory: marge\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "for i in range(len(folders)):\n",
    "    print(\"Working on directory: \" + folders[i])\n",
    "    files = glob.glob(train_data_pth + folders[i] + '/*.jpg')\n",
    "\n",
    "    # We will take a random sampling of the files\n",
    "    files = np.random.choice(files,n_input,replace=False)\n",
    "    \n",
    "    for f in files:\n",
    "        head, file = os.path.split(f)\n",
    "        filename, file_extension = os.path.splitext(file)\n",
    "        img = Image.open(f)\n",
    "        org_width, org_height = img.size\n",
    "        for k in range(random_permutations_per_image):\n",
    "            # Pick which changes we make:\n",
    "            picknum = np.random.rand()\n",
    "            # Flip half of the images\n",
    "            if k>0 and (picknum > 0.5):\n",
    "                # Mirror\n",
    "                img = mirror(img)                \n",
    "            \n",
    "            # Skew 30% of the imagess\n",
    "            if k>1 and (picknum > 0.7):  \n",
    "                # skew\n",
    "                m = np.random.uniform(-skew_fraction,skew_fraction)\n",
    "                xshift = int(round(abs(m) * org_width))\n",
    "                new_width = org_width + xshift\n",
    "                img = img.transform((new_width, org_height), Image.AFFINE,\n",
    "                        (1, m, -xshift if m > 0 else 0, 0, 1, 0), Image.BICUBIC)\n",
    "                # Crop the skew\n",
    "                if (m < 0):\n",
    "                    crop_dims = (xshift,0,org_width-xshift,org_height)\n",
    "                else:\n",
    "                    crop_dims = (0,0,org_width-xshift,org_height)\n",
    "                img = img.crop(crop_dims)\n",
    "            # Zoom 80% of the images\n",
    "            if k>1 and (picknum > 0.2): \n",
    "                # Zoom\n",
    "                z = np.random.uniform(-zoom_fraction,zoom_fraction)\n",
    "                org_width, org_height = img.size\n",
    "                basewidth = int(org_width*(1+z))\n",
    "                wpercent = (basewidth/float(org_width))\n",
    "                hsize = int((float(org_height)*float(wpercent)))\n",
    "                if basewidth > org_width:\n",
    "                    #Zoom out by padding\n",
    "                    old_size = img.size\n",
    "                    new_size = (basewidth, hsize)\n",
    "                    new_im = Image.new(\"RGB\", new_size)   ## luckily, this is already black!\n",
    "                    new_im.paste(img, (int((new_size[0]-old_size[0])/2),int((new_size[1]-old_size[1])/2)))\n",
    "                    img = new_im\n",
    "                    \n",
    "                else:\n",
    "                    #Zoom in by cropping\n",
    "                    crop_dims = ((org_width-basewidth)/2,(org_height - hsize)/2,(org_width-basewidth)/2 + basewidth, (org_height - hsize)/2 + hsize)\n",
    "                    img = img.crop(crop_dims)\n",
    "                \n",
    "        \n",
    "        \n",
    "            img2 = img.resize((img_width,img_height), Image.ANTIALIAS)\n",
    "           \n",
    "            img2.save(train_data_out + folders[i] + \"/\" + filename + \"_{}_prep\".format(k) + file_extension)\n",
    "\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on directory: bart\n",
      "Working on directory: hommer\n",
      "Working on directory: lisa\n",
      "Working on directory: marge\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(17)\n",
    "for i in range(len(folders)):\n",
    "    print(\"Working on directory: \" + folders[i])\n",
    "    files = glob.glob(validation_data_pth + folders[i] + '/*.jpg')\n",
    "\n",
    "    # We will take a random sampling of the files\n",
    "    files = np.random.choice(files,n_valid,replace=False)\n",
    "    \n",
    "    for f in files:\n",
    "        head, file = os.path.split(f)\n",
    "        filename, file_extension = os.path.splitext(file)\n",
    "        img = Image.open(f)\n",
    "        org_width, org_height = img.size\n",
    "        for k in range(random_permutations_per_image):\n",
    "            # Pick which changes we make:\n",
    "            \n",
    "            # Flip half of the images\n",
    "            if (np.random.rand() > 0.5):\n",
    "                # Mirror\n",
    "                img = mirror(img)                \n",
    "            \n",
    "            # Skew 30% of the imagess\n",
    "            if (np.random.rand() > 0.7):  \n",
    "                # skew\n",
    "                m = np.random.uniform(-skew_fraction,skew_fraction)\n",
    "                xshift = int(round(abs(m) * org_width))\n",
    "                new_width = org_width + xshift\n",
    "                img = img.transform((new_width, org_height), Image.AFFINE,\n",
    "                        (1, m, -xshift if m > 0 else 0, 0, 1, 0), Image.BICUBIC)\n",
    "            \n",
    "            # Zoom 80% of the images\n",
    "            if (np.random.rand() > 0.2): \n",
    "                # Zoom\n",
    "                z = np.random.uniform(-zoom_fraction,zoom_fraction)\n",
    "                basewidth = int(org_width*(1+z))\n",
    "                wpercent = (basewidth/float(org_width))\n",
    "                hsize = int((float(org_height)*float(wpercent)))\n",
    "                img = img.resize((basewidth,hsize), Image.ANTIALIAS)\n",
    "        \n",
    "        \n",
    "            width, height = img.size\n",
    "\n",
    "            # Pick a random location to crop\n",
    "            start_width = np.random.randint(0,int((width - img_width)/2))\n",
    "            start_height = np.random.randint(0,int((height - img_height)/2))\n",
    "\n",
    "            crop_dims = (start_width,start_height,img_width+start_width,img_height+start_height)\n",
    "            img2 = img.crop(crop_dims)\n",
    "           \n",
    "            img2.save(validation_data_out + folders[i] + \"/\" + filename + \"_{}_prep\".format(k) + file_extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
